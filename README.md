# Special Session for WCCI 2026

# Deep Neural Architecture Generation for Generative Models and Adversarial Learning for Image/Video/Audio/Text Processing 

Abstract

Generative Adversarial Networks (GANs) have become new hotspots of Artificial Intelligence. Various GAN-inspired and variant models (e.g. conditional GAN (cGAN), auxiliary classifier GAN (AC-GAN), bidirectional GAN (BiGAN), semi-supervised GAN and variational autoencoder GAN (VAE-GAN)) have been developed for image generation, segmentation, detection and classification, as well as video/audio synthesis/retrieval/restoration/domain adaptation. Such developments have contributed to a variety of applications, such as personalized story-telling, animated movie generation, building/interior design, e-learning, medical diagnosis, surveillance, agriculture, deepfake generation, urban land use detection, and underwater/forest observation using multispectral/hyperspectral images. The design of new and effective variant architectures of GANs has attracted significant attention.

In parallel, reinforcement learning and evolutionary algorithms have demonstrated superior performance in automated deep neural architecture generation. As popular reinforcement learning methods, deep Q-learning, Proximal Policy Optimization (PPO), actor-critic and Deep Deterministic Policy Gradient (DDPG) algorithms, have been adopted in various existing studies for optimal network architecture generation and hyper-parameter optimization. A variety of recent state-of-the-art swarm intelligence algorithms (e.g. Sparrow Search Algorithm, Tree Search Optimization and Marine Predators Algorithm) and hybrid methods (e.g. evolutionary algorithms combined with reinforcement learning models) have also been developed and deployed in single, multi and many-objective optimization problems for neural architecture search for image, video, sound and text classification problems. 

This special issue aims to stimulate research and discussion on GAN-inspired methods as well as automatic machine learning methods for GAN architecture generation for a variety of image/video/signal and natural language processing problems. 

It also aims to stimulate new developments to address gaps such as deep network generation for GANs as well as other hybrid/cascaded architectures with residual/dense connectivity to tackle vanishing gradients for complex image processing tasks such as image description and visual question generation.

Potential topics include, but are not limited to, the following:

•	Semantic segmentation

•	Object detection 

•	Scene classification

•	Image super-resolution

•	Image denoising

•	Image description generation (image-to-text translation)

•	Visual question generation/answering

•	Text-to-image generation

•	Image classification

•	Image retrieval 

•	Human or object attribute prediction

•	Deepfake generation and classification

•	Human action recognition

•	Bioinformatics and medical diagnosis

•	Machine translation and language generation

•	Sound classification

•	Evolving deep neural network generation for video/image/audio/signal/text processing and classification

•	Hybrid optimization methods (e.g. swarm intelligence algorithms combined with reinforcement learning) for deep architecture generation

•	Any other optimal topology and hyper-parameter identification for classification/regression and ensemble learning models


The special session integrates rising topics such as deep learning and generative AI models with reinforcement learning and evolutionary computation, and shows strong relevance to IJCNN 2025 conference themes, e.g. Generative AI Models, Large-Scale Neural Networks, Neural Engineering, Neural Networks for Sciences, Perceptual Neural Networks, Reinforcement Learning, Transformer Networks, and Neural Network Applications. 

We aim to attract a large number of high quality submissions from research communities with a variety of research backgrounds to stimulate discussions in the proposed and aforementioned relevant conference themes, as well as identify new directions and solutions with the attempt to address research gaps and diverse real-world challenges.


Organizers

Professor Li Zhang 
Department of Computer Science, Royal Holloway, University of London, Surrey, TW20 0EX, UK. 
Email: li.zhang@rhul.ac.uk

Professor Chee Peng Lim 
Department of Computing Technologies, Swinburne University of Technology, VIC 3122, Australia
Email: cplim@swin.edu.au

Professor Jungong Han 
Department of Computer Science, University of Sheffield, Sheffield, S10 2TN, UK. 
Email: jungong.han@sheffield.ac.uk

Associate Professor Houshyar Asadi
Institute for Intelligent Systems Research and Innovation, Deakin University, Waurn Ponds, VIC 3216, Australia
Email: houshyar.asadi@deakin.edu.au


Important dates

31 January: Paper submission deadline (23:59, anywhere on Earth, i.e. UTC-12) – no extension will be given.

15 March: Paper acceptance notification

15 April: Camera-ready papers

21 June: Tutorials

24 June: Industry Day

22- 26 June: Conference



